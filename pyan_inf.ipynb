{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81852bf2d3d34e368a52e1d504b23707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/saiakarsh/envs/augnito/lib/python3.9/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Primock.SpeakerDiarization.full' found in /data/saiakarsh/codes/diar_aug/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/saiakarsh/envs/augnito/lib/python3.9/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f7c717b17f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=True\n",
    ")\n",
    "pretrained_pipeline.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [51:25<00:00, 54.14s/it] \n"
     ]
    }
   ],
   "source": [
    "out_dir = \"timestamps_pyan_diar_pretrained\"\n",
    "os.mkdir(out_dir)\n",
    "\n",
    "src_dir = \"primock57/output/mixed_audio/\"\n",
    "for audio in tqdm(os.listdir(src_dir)):\n",
    "    audio_path = os.path.join(src_dir, audio)\n",
    "    diarization = pretrained_pipeline(audio_path)\n",
    "    meta = []\n",
    "    for seg, seg_id, spk_id in diarization.itertracks(yield_label=True):\n",
    "        if len(meta) > 0 and meta[-1][2] == spk_id: # last spk_id == spk_id\n",
    "            meta[-1][1] = seg.end\n",
    "        else:\n",
    "            meta.append([seg.start, seg.end, spk_id])\n",
    "    with open(os.path.join(out_dir, audio[:-3] + \"txt\"), 'w') as f:\n",
    "        for st, en, spk_id in meta:\n",
    "            f.write(f\"{st:.3f},{en:.3f},{spk_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f7b9bbefa90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.audio.pipelines import SpeakerDiarization\n",
    "\n",
    "finetuned_model = \"/data/saiakarsh/codes/diar_aug/lightning_logs/version_0/checkpoints/epoch=19.ckpt\"\n",
    "best_segmentation_threshold = 0.5952774382125149\n",
    "best_clustering_threshold = 0.7995650252252342\n",
    "\n",
    "finetuned_pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")\n",
    "\n",
    "finetuned_pipeline.instantiate({\n",
    "    \"segmentation\": {\n",
    "        \"threshold\": best_segmentation_threshold,\n",
    "        \"min_duration_off\": 0.0,\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        \"method\": \"centroid\",\n",
    "        \"min_cluster_size\": 15,\n",
    "        \"threshold\": best_clustering_threshold,\n",
    "    },\n",
    "})\n",
    "\n",
    "finetuned_pipeline.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [1:26:24<00:00, 90.95s/it] \n"
     ]
    }
   ],
   "source": [
    "out_dir = \"timestamps_pyan_diar_finetuned\"\n",
    "os.mkdir(out_dir)\n",
    "\n",
    "src_dir = \"primock57/output/mixed_audio/\"\n",
    "for audio in tqdm(os.listdir(src_dir)):\n",
    "    audio_path = os.path.join(src_dir, audio)\n",
    "    diarization = finetuned_pipeline(audio_path)\n",
    "    meta = []\n",
    "    for seg, seg_id, spk_id in diarization.itertracks(yield_label=True):\n",
    "        if len(meta) > 0 and meta[-1][2] == spk_id: # last spk_id == spk_id\n",
    "            meta[-1][1] = seg.end # combine timestamps if last spk_id is same as current one\n",
    "        else:\n",
    "            meta.append([seg.start, seg.end, spk_id])\n",
    "    with open(os.path.join(out_dir, audio[:-3] + \"txt\"), 'w') as f:\n",
    "        for st, en, spk_id in meta:\n",
    "            f.write(f\"{st:.3f},{en:.3f},{spk_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
